{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from Marsland's ML code\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Perceptron Class Definition\n",
    "class pcn:\n",
    "\n",
    "\tdef __init__(self,inputs,targets,outfid):   # create and initialize network\n",
    "            self.fid = outfid\n",
    "            self.trace = False\n",
    "            if np.ndim(inputs)>1:\n",
    "                self.nIn = np.shape(inputs)[1]    # num. of input nodes\n",
    "            else: \n",
    "                self.nIn = 1\n",
    "            if np.ndim(targets)>1:\n",
    "                self.nOut = np.shape(targets)[1]  # num. of output nodes\n",
    "            else:\n",
    "                self.nOut = 1\n",
    "            self.nData = np.shape(inputs)[0]          # num. of data examples\n",
    "            # Initialise weights:  nIn+1 x nOut weight matrix (+1 for bias)\n",
    "                    #                      random wts. between +/-0.05\n",
    "            self.weights = np.random.rand(self.nIn+1,self.nOut)*0.1-0.05\n",
    "            ####Different Weight Initialization\n",
    "            \n",
    "            self.fid.write(\"Initial Weights:\\n {} \\n\".format(self.weights) + \"\\n\")\n",
    "\n",
    "\tdef pcntrain(self,inputs,targets,eta,nIterations):\n",
    "            self.nData = np.shape(inputs)[0]          # num. of data examples\n",
    "\t\t# Add the inputs that match the bias node\n",
    "            inputs = np.concatenate((inputs,-np.ones((self.nData,1))),axis=1)\n",
    "\t\t# Training\n",
    "\t\t# change = range(self.nData)  # use iff re-order training data each epoch\n",
    "            for n in range(nIterations):\n",
    "                self.activations = self.pcnfwd(inputs) # one epoch's results\n",
    "                self.weights -= eta*np.dot(np.transpose(inputs),self.activations-targets)\n",
    "\t\t   # Randomise order of inputs\n",
    "\t\t   #np.random.shuffle(change)\n",
    "\t\t   #inputs = inputs[change,:]\n",
    "\t\t   #targets = targets[change,:]\n",
    "            \n",
    "            \n",
    "            self.fid.write(\"Final Weights:\\n {} \\n\".format(self.weights) + \"\\n\")\n",
    "            \n",
    "            ###########----Manohar Anumolu (UID 115733039)-----########\n",
    "            self.fid.write(\"Learning Rate:\\n {} \\n\".format(eta) + \"\\n\" + \"\\n\" )\n",
    "            self.fid.write(\"Number of Epochs:\\n {} \\n\".format(nIterations) + \"\\n\" + \"\\n\" )\n",
    "            \n",
    "            ##########----------------------------------------#########\n",
    "\t\t#return self.weights\n",
    "\n",
    "\tdef pcnfwd(self,inputs):                            # Run the network (batch mode)\n",
    "            activations =  np.dot(inputs,self.weights)  # compute weighted node inputs\n",
    "            return np.where(activations>0,1,0)          # return node outputs 0/1 \n",
    "\n",
    "        # Confusion Matrix layout:           targets\n",
    "        #                                      0 1\n",
    "        #                                      x x  0  actual\n",
    "        #                                      x x  1\n",
    "\n",
    "\tdef confmat(self,inputs,targets,msg):       # generate the confusion matrix\n",
    "\t\t# Add the inputs that match the bias node\n",
    "\t\t# inputs = np.concatenate((inputs,-np.ones((self.nData,1))),axis=1)    # BAD \n",
    "            inputs = np.concatenate((inputs,-np.ones((inputs.shape[0],1))),axis=1) # FIX\n",
    "            outputs = np.dot(inputs,self.weights) \n",
    "            if self.trace:        # Tracing: show target and actual outputs \n",
    "                self.fid.write(msg + \": target actual\\n\")\n",
    "                for i in range(self.nData):\n",
    "                    if outputs[i] > 0:\n",
    "                        actual = 1\n",
    "                    else:\n",
    "                        actual = 0\n",
    "                    self.fid.write(\"   {}   {}\\n\".format(int(targets[i][0]),actual))\n",
    "                self.fid.write(\"\\n\") \n",
    "            nClasses = np.shape(targets)[1] \n",
    "            if nClasses==1:\n",
    "                nClasses = 2\n",
    "                outputs = np.where(outputs>0,1,0)\n",
    "            else:\n",
    "\t\t\t# 1-of-N encoding\n",
    "                outputs = np.argmax(outputs,1)\n",
    "                targets = np.argmax(targets,1) \n",
    "            cm = np.zeros((nClasses,nClasses))\n",
    "            for i in range(nClasses):         # for each actual output\n",
    "                for j in range(nClasses):      # for each target value\n",
    "                    cm[i,j] = np.sum(np.where(outputs==i,1,0)*np.where(targets==j,1,0)) \n",
    "                      # rows are actual values, cols are target values \n",
    "            self.fid.write(msg + \"confusion matrix:\\n {} \\n\".format(cm))\n",
    "            self.fid.write(\"Fraction correct: {} \\n\".format(np.trace(cm)/np.sum(cm)) + \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt(\"/Users/anumolubhargav/Documents/Machine Learning/Homework1/radarData.txt\",delimiter =\",\")\n",
    "# print(data)\n",
    "np.shape(data)\n",
    "#Observed 351 Rows and 35 Columns---last column is output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into test and train data--take every 5th sample for testing\n",
    "test = data[::5]\n",
    "\n",
    "train = np.delete(data, np.s_[::5], axis = 0)\n",
    "\n",
    "#Split into test and train inputs and outputs\n",
    "\n",
    "X_train = np.delete(train, -1, 1)\n",
    "# print(np.shape(X_train))\n",
    "# print(\" X Train : \" )\n",
    "# print(X_train)\n",
    "\n",
    "Y_train = np.delete(train, np.s_[:-1], 1)\n",
    "# print(np.shape(Y_train))\n",
    "# print(\" Y Train : \" )\n",
    "# print(Y_train)\n",
    "\n",
    "X_test = np.delete(test, -1, 1)\n",
    "# print(np.shape(X_test))\n",
    "# print(\" X Test : \" )\n",
    "# print(X_test)\n",
    "\n",
    "Y_test = np.delete(test, np.s_[:-1], 1)\n",
    "# print(np.shape(Y_test))\n",
    "# print(\" Y Test : \" )\n",
    "# print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Required in output file\n",
    "\n",
    "#1.Number of training examples\n",
    "#2.Number of testing examples\n",
    "#3.Learning Rate\n",
    "#4.Number of epochs\n",
    "\n",
    "#5. Initial Pre-Training Weights\n",
    "#6. Confusion Matrix - pre-training on training and testing data\n",
    "\n",
    "#7. Post training Weights\n",
    "#8. Confusion Matrix - post-training on training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the neural network\n",
    "file = open('/Users/anumolubhargav/Documents/Machine Learning/Homework1/Results.txt', 'w+')\n",
    "\n",
    "# pre_train = X_train.copy() #for the pre-trained forward pass for training data\n",
    "# pre_test = X_test.copy()   # for the pre-trained forward pass for testing data\n",
    "\n",
    "\n",
    "####-NETWORK INITIALIZATION \n",
    "#Initialize network to generate pre-trained weights\n",
    "model = pcn(X_train,Y_train, file)\n",
    "\n",
    "##----------------------------------------------------------------------------------##\n",
    "# TRYING FORWARD PASS BEFORE TRAINING ON TESTING AND TRAINING DATA\n",
    "#Add bias nodes to all inputs (for both pre_test and pre_train)\n",
    "# pre_train = np.concatenate((pre_train,-np.ones((pre_train.shape[0],1))),axis=1)\n",
    "# pre_trest = np.concatenate((pre_test,-np.ones((pre_test.shape[0],1))),axis=1)\n",
    "\n",
    "# #Run the forward pass on pre-trained weights for training data\n",
    "# pre_trained_training_output = model.pcnfwd(pre_train)\n",
    "\n",
    "# #Run the forward pass on pre_trained weights for testing data\n",
    "# pre_trained_testing_output = model.pcnfwd(pre_test)\n",
    "##---------------------------------------------------------------------------------##\n",
    "\n",
    "#Find the confusion matrix for pre-trained training data\n",
    "model.confmat(X_train,Y_train,\"Pre-Trained Training Data -- \")\n",
    "\n",
    "#Find the confusion matrix for pre-trained testing data\n",
    "model.confmat(X_test,Y_test,\"Pre-Trained Testing Data -- \")\n",
    "\n",
    "#TRAINING THE NEURAL NETWORK\n",
    "file.write(\"Training the neural network now....... \\n\\n\\n\")\n",
    "model.pcntrain(X_train, Y_train,0.25,500) #--train the neural network\n",
    "file.write(\"Number of Training Examples: {}\".format(np.shape(X_train)[0])+ \"\\n\")\n",
    "\n",
    "#Find the confusion matrix for post-trained training data\n",
    "model.confmat(X_train,Y_train,\"Post_Trained Training Data --\")\n",
    "\n",
    "#Find the confusion matrix for post-trained testing data\n",
    "model.confmat(X_test,Y_test,\"Post-Trained Testing Data -- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Trying Q1 Part 3 -----Hmm. Seems to be a Value Error have to look into it. \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "Q_data = [[1,1,-1,-1,1],[-1,-1,1,1,1],[1,-1,1,-1,0],[-1,1,-1,1,0]]\n",
    "\n",
    "\n",
    "Q_input = np.delete(Q_data,-1,1)\n",
    "Q_target = np.delete(Q_data,np.s_[:-1],1)\n",
    "\n",
    "file1 = open('/Users/anumolubhargav/Documents/Machine Learning/Homework1/Q1Check.txt', 'w+')\n",
    "model1 = pcn(Q_input,Q_target,file1)\n",
    "\n",
    "model1.confmat(Q_input,Q_target,\"Q1 before train: \")\n",
    "\n",
    "model1.pcntrain(Q_input,Q_target,1,5)\n",
    "\n",
    "model1.confmat(Q_input,Q_target,\"Q1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.055268740000000004\n"
     ]
    }
   ],
   "source": [
    "print(-0.03894991+0.03477987-0.01046701+0.02967897+0.04022682)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
