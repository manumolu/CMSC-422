{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID3-like decision tree induction\n",
    "# Modified from Chap. 12, Machine Learning, Stephen Marsland, 2015\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class dtree:                       # decision tree class\n",
    "\tdef __init__(self,outfid):      # constructor\n",
    "\t\t\"\"\" constructor for DT class \"\"\"\n",
    "\t\tself.fid = outfid            # output file\n",
    "\t\tself.attr_nodes = 0\n",
    "\t\tself.leaf_nodes = 0\n",
    "\n",
    "\tdef read_data(self,filename):   # reads attrs, data in file filename (string)\n",
    "\t\tfid = open(filename,\"r\")  \n",
    "\t\tdata = []   # list of input strings, where each sublist is from one line\n",
    "\t\td = []      # list of input data\n",
    "\t\tfor line in fid.readlines():\n",
    "\t\t\td.append(line.strip())       # remove leading/trailing white space\n",
    "\t\tfor d1 in d:\n",
    "\t\t\tdata.append(d1.split(\",\"))   # splits d1 using ',' as delimiter\n",
    "\t\tfid.close() \n",
    "\t\tself.featureNames = data[0]                # list of atr names (1st line fid)\n",
    "\t\tself.featureNames = self.featureNames[:-1] # remove output class name\n",
    "\t\tdata = data[1:]                 # list of input examples (delete data header)\n",
    "\t\tself.classes = []               \n",
    "\t\tfor d in range(len(data)):\n",
    "\t\t\tself.classes.append(data[d][-1])\n",
    "\t\t\tdata[d] = data[d][:-1] \n",
    "\t\treturn data,self.classes,self.featureNames\n",
    "\n",
    "\tdef classify(self,tree,datapoint):      # use tree to classify pattern datapoint\n",
    "\t\tif type(tree) == type(\"string\"):   # have reached a leaf\n",
    "\t\t\treturn tree                # return the classification\n",
    "\t\telse:\n",
    "\t\t\ta = tree.keys()[0]         # first node in tree\n",
    "\t\t\tfor i in range(len(self.featureNames)):   # for each input feature i\n",
    "\t\t\t\tif self.featureNames[i]==a:       \n",
    "\t\t\t\t\tbreak\n",
    "\t\t\ttry:\n",
    "\t\t\t\tt = tree[a][datapoint[i]]\n",
    "\t\t\t\treturn self.classify(t,datapoint)\n",
    "\t\t\texcept:\n",
    "\t\t\t\treturn None\n",
    "\n",
    "\tdef classifyAll(self,tree,data):        # use tree to classify all examples in data\n",
    "\t\tresults = []\n",
    "\t\tfor i in range(len(data)):         # for each example in data\n",
    "\t\t\tresults.append(self.classify(tree,data[i]))  # run i through the tree\n",
    "\t\treturn results\n",
    "\n",
    "\tdef make_tree(self,data,classes,featureNames,maxlevel=-1,level=0,forest=0):\n",
    "\t\t# main function; recursively constructs the tree\n",
    "\t\tnData = len(data)          # number of examples\n",
    "\t\tnFeatures = len(data[0])   # number of input features or attributes\n",
    "\t\ttry: \n",
    "\t\t\tself.featureNames                  # if no feature names\n",
    "\t\texcept:\n",
    "\t\t\tself.featureNames = featureNames   # use those given as input\n",
    "\t\tnewClasses = []            # list of unique possible output classes\n",
    "\t\tfor aclass in classes:     # newClasses = unique class names; e.g., ['y', 'n']?\n",
    "\t\t\tif newClasses.count(aclass)==0:    # if aclass is not in newClasses\n",
    "\t\t\t\tnewClasses.append(aclass)  # then add aclass to newClasses \n",
    "\t\t# compute the default class and total entropy of data\n",
    "\t\tfrequency = np.zeros(len(newClasses)) \n",
    "\t\ttotalEntropy = 0           # entropy of data\n",
    "\t\ttotalGini = 0              # Gini value of data\n",
    "\t\tindex = 0\n",
    "\t\tfor aclass in newClasses:  # for each unique output class\n",
    "\t\t\tfrequency[index] = classes.count(aclass)  # num times aclass in targets\n",
    "\t\t\ttotalEntropy += self.calc_entropy(float(frequency[index])/nData)\n",
    "\t\t\ttotalGini += (float(frequency[index])/nData)**2 \n",
    "\t\t\tindex += 1 \n",
    "\t\ttotalGini = 1 - totalGini\n",
    "\t\tdefault = newClasses[np.argmax(frequency)]  # FIX2: replaces next line\n",
    "\t\t\t#default = classes[np.argmax(frequency)]    # BAD? ******\n",
    "\t\tif nData==0 or nFeatures == 0 or (maxlevel>=0 and level>maxlevel):\n",
    "\t\t\treturn default       # have reached an empty branch\n",
    "\t\telif frequency[np.argmax(frequency)] == nData:   # FIX3: if all data in one class\n",
    "\t\t\treturn newClasses[np.argmax(frequency)]  # FIX3: return that class\n",
    "\t\t#elif classes.count(classes[0]) == nData:        # BAD? ****** \n",
    "\t\t#\treturn classes[0]                        # BAD? ******\n",
    "\t\telse:                        # else choose which input attribute is best\t\n",
    "\t\t\tgain = np.zeros(nFeatures)     # entropy gains for features\n",
    "\t\t\tggain = np.zeros(nFeatures)    # Gini gains for features\n",
    "\t\t\tfeatureSet = range(nFeatures)  # indices of features (input atrs)\n",
    "\t\t\tif forest != 0:\n",
    "\t\t\t\tnp.random.shuffle(featureSet)\n",
    "\t\t\t\tfeatureSet = featureSet[0:forest]\n",
    "\t\t\tfor feature in featureSet:     # for each input feature\n",
    "\t\t\t\tg,gg = self.calc_info_gain(data,classes,feature)\n",
    "\t\t\t\tgain[feature] = totalEntropy - g\n",
    "\t\t\t\tggain[feature] = totalGini - gg \n",
    "\t\t\tbestFeature = np.argmax(gain) # input feature with highest info gain\n",
    "\t\t\ttree = {featureNames[bestFeature]:{}}  # start dict representing tree\n",
    "\t\t\tvalues = []                   # values that bestFeature can take\n",
    "\t\t\tfor datapoint in data:\n",
    "\t\t\t\t#if datapoint[feature] not in values:      # BAD? ******\n",
    "\t\t\t\tif datapoint[bestFeature] not in values:   # FIX1: replaces previous line\n",
    "\t\t\t\t\tvalues.append(datapoint[bestFeature])\n",
    "\t\t\tfor value in values:     # find datapoints with each feature value\n",
    "\t\t\t\tnewData = []\n",
    "\t\t\t\tnewClasses = []\n",
    "\t\t\t\tindex = 0\n",
    "\t\t\t\tfor datapoint in data:\n",
    "\t\t\t\t\tif datapoint[bestFeature]==value:\n",
    "\t\t\t\t\t\tif bestFeature==0:\n",
    "\t\t\t\t\t\t\tnewdatapoint = datapoint[1:]\n",
    "\t\t\t\t\t\t\tnewNames = featureNames[1:]\n",
    "\t\t\t\t\t\telif bestFeature==nFeatures:\n",
    "\t\t\t\t\t\t\tnewdatapoint = datapoint[:-1]\n",
    "\t\t\t\t\t\t\tnewNames = featureNames[:-1]\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tnewdatapoint = datapoint[:bestFeature]\n",
    "\t\t\t\t\t\t\tnewdatapoint.extend(datapoint[bestFeature+1:])\n",
    "\t\t\t\t\t\t\tnewNames = featureNames[:bestFeature]\n",
    "\t\t\t\t\t\t\tnewNames.extend(featureNames[bestFeature+1:])\n",
    "\t\t\t\t\t\tnewData.append(newdatapoint)\n",
    "\t\t\t\t\t\tnewClasses.append(classes[index])\n",
    "\t\t\t\t\tindex += 1 \n",
    "\t\t\t\t# Now recurse to the next level\t\n",
    "\t\t\t\tsubtree = self.make_tree(newData,newClasses,newNames,maxlevel,level+1,forest) \n",
    "\t\t\t\ttree[featureNames[bestFeature]][value] = subtree  # add subtree to tree \n",
    "\t\t\treturn tree\n",
    "\n",
    "\tdef printTree(self,tree,spacing):     # display indented tree\n",
    "\t\tfid = self.fid                   # fid = output file, spacing = indentation\n",
    "\t\tif type(tree) == dict:           # if it's a tree/subtree\n",
    "\t\t\tself.attr_nodes += 1\n",
    "\t\t\tfid.write(\"{} {}?\".format(spacing,tree.keys()[0]) + \"\\n\")  # atr name\n",
    "\t\t\tfor item in tree.values()[0].keys():          # for each value of atr\n",
    "\t\t\t\t#print spacing, item\n",
    "\t\t\t\tfid.write(\"{} {}\".format(spacing,item) + \"\\n\")         # write val name\n",
    "\n",
    "\t\t\t\tself.printTree(tree.values()[0][item], spacing + \"\\t\") # write subtrees\n",
    "\t\telse:\n",
    "\t\t\tself.leaf_nodes += 1\n",
    "\t\t\tfid.write(\"{} {} {}\".format(spacing,\"\\t->  \",tree) + \"\\n\") # write classif\n",
    "\t\treturn self.attr_nodes, self.leaf_nodes\n",
    "\n",
    "\tdef calc_entropy(self,p):\n",
    "\t\tif p!=0:\n",
    "\t\t\treturn -p * np.log2(p)\n",
    "\t\telse:\n",
    "\t\t\treturn 0\n",
    "\n",
    "\tdef calc_info_gain(self,data,classes,feature): \n",
    "\t\t# Calculates information gain based on both entropy and Gini impurity\n",
    "\t\t\t# data = data samples, classes = XX, feature = XX\n",
    "\t\tgain = 0             # info gain, entropy\n",
    "\t\tggain = 0            # info gain, Gini\n",
    "\t\tnData = len(data)    # number of data samples\n",
    "\t\tvalues = []          # values that feature can take\n",
    "\t\tfor datapoint in data:\n",
    "\t\t\tif datapoint[feature] not in values:\n",
    "\t\t\t\tvalues.append(datapoint[feature]) \n",
    "\t\tfeatureCounts = np.zeros(len(values))\n",
    "\t\tentropy = np.zeros(len(values))\n",
    "\t\tgini = np.zeros(len(values))\n",
    "\t\tvalueIndex = 0\n",
    "\t\t# Find where those values appear in data[feature] and the corresponding class\n",
    "\t\tfor value in values:\n",
    "\t\t\tdataIndex = 0\n",
    "\t\t\tnewClasses = []\n",
    "\t\t\tfor datapoint in data:\n",
    "\t\t\t\tif datapoint[feature]==value:\n",
    "\t\t\t\t\tfeatureCounts[valueIndex]+=1\n",
    "\t\t\t\t\tnewClasses.append(classes[dataIndex])\n",
    "\t\t\t\tdataIndex += 1 \n",
    "\t\t\t# Get the values in newClasses\n",
    "\t\t\tclassValues = []\n",
    "\t\t\tfor aclass in newClasses:\n",
    "\t\t\t\tif classValues.count(aclass)==0:\n",
    "\t\t\t\t\tclassValues.append(aclass) \n",
    "\t\t\tclassCounts = np.zeros(len(classValues))\n",
    "\t\t\tclassIndex = 0\n",
    "\t\t\tfor classValue in classValues:\n",
    "\t\t\t\tfor aclass in newClasses:\n",
    "\t\t\t\t\tif aclass == classValue:\n",
    "\t\t\t\t\t\tclassCounts[classIndex]+=1 \n",
    "\t\t\t\tclassIndex += 1 \n",
    "\t\t\tfor classIndex in range(len(classValues)):\n",
    "\t\t\t\tentropy[valueIndex] += self.calc_entropy(float(classCounts[classIndex])/np.sum(classCounts))\n",
    "\t\t\t\tgini[valueIndex] += (float(classCounts[classIndex])/np.sum(classCounts))**2 \n",
    "\t\t\t# Computes both the Gini gain and the entropy\n",
    "\t\t\tgain = gain + float(featureCounts[valueIndex])/nData * entropy[valueIndex]\n",
    "\t\t\tggain = ggain + float(featureCounts[valueIndex])/nData * gini[valueIndex]\n",
    "\t\t\tvalueIndex += 1\n",
    "\t\treturn gain, 1-ggain\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To be done:\n",
    "\n",
    "# 1. Output the Induced Tree\n",
    "# 2. Total Number of Nodes in the tree (including leaves)\n",
    "# 3. Number of Leaves in the tree\n",
    "# 4. No. of Training examples used\n",
    "# 5. Number of Examples classified correctly by induced tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initiate a class instance:\n",
    "fid = open('/Users/akshatpant/Downloads/Homework3/ResultsID3.txt', 'w')\n",
    "Decision_Tree = dtree(fid)\n",
    "\n",
    "#Read the file data\n",
    "data, classes, feature_names = Decision_Tree.read_data('/Users/akshatpant/Downloads/Homework3/party.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make the Tree\n",
    "ID3tree = Decision_Tree.make_tree(data,classes,feature_names,maxlevel=-1,level=0,forest=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'physician-fee-freeze': {'a': {'mx-missile': {'a': 'republican',\n",
       "    'n': 'democrat',\n",
       "    'y': {'anti-satellite-test-ban': {'a': 'democrat',\n",
       "      'n': 'republican',\n",
       "      'y': 'democrat'}}}},\n",
       "  'n': {'adoption-of-the-budget-resolution': {'a': 'democrat',\n",
       "    'n': {'education-spending': {'a': 'republican',\n",
       "      'n': {'synfuels-corporation-cutback': {'n': {'religious-groups-in-schools': {'n': {'crime': {'n': 'democrat',\n",
       "            'y': 'republican'}},\n",
       "          'y': 'democrat'}},\n",
       "        'y': 'democrat'}},\n",
       "      'y': 'democrat'}},\n",
       "    'y': 'democrat'}},\n",
       "  'y': {'synfuels-corporation-cutback': {'a': 'republican',\n",
       "    'n': {'duty-free-exports': {'a': 'republican',\n",
       "      'n': {'adoption-of-the-budget-resolution': {'n': 'republican',\n",
       "        'y': {'export-administration-act-south-africa': {'a': {'handicapped-infants': {'n': 'democrat',\n",
       "            'y': 'republican'}},\n",
       "          'y': 'republican'}}}},\n",
       "      'y': {'immigration': {'n': {'export-administration-act-south-africa': {'a': {'water-project-cost-sharing': {'n': 'democrat',\n",
       "            'y': 'republican'}},\n",
       "          'n': 'republican',\n",
       "          'y': 'democrat'}},\n",
       "        'y': 'republican'}}}},\n",
       "    'y': {'adoption-of-the-budget-resolution': {'a': 'democrat',\n",
       "      'n': {'el-salvador-aid': {'n': 'democrat',\n",
       "        'y': {'export-administration-act-south-africa': {'a': {'handicapped-infants': {'n': 'republican',\n",
       "            'y': 'democrat'}},\n",
       "          'n': {'superfund-right-to-sue': {'n': 'democrat',\n",
       "            'y': {'water-project-cost-sharing': {'n': {'handicapped-infants': {'n': 'democrat',\n",
       "                'y': 'republican'}},\n",
       "              'y': 'republican'}}}},\n",
       "          'y': 'republican'}}}},\n",
       "      'y': {'anti-satellite-test-ban': {'n': 'democrat',\n",
       "        'y': 'republican'}}}}}}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID3tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 105)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = Decision_Tree.classifyAll(ID3tree,data)\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in range(0,len(predict)):\n",
    "    if predict[i] == classes[i]:\n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "Accuracy = (count/435)*100\n",
    "\n",
    "fid.write(\"The number of Attribute Nodes is 24 \\n\\n\\n\\n\")\n",
    "fid.write(\"The number of Leaf Nodes is 35 \\n\\n\\n\")\n",
    "fid.write(\"The total number of nodes is 59 \\n\\n\\n\")\n",
    "fid.write(\"The number of training examples is 435 \\n\\n\\n\")\n",
    "fid.write(\"The accuracy is 100%!\\n\\n\\n\")\n",
    "# len(data) found out to be 435 examples\n",
    "fid.write(\"The number of training examples is 435\\n\\n\\n\")\n",
    "#Print the Tree\n",
    "Decision_Tree.printTree(ID3tree,\"  \")\n",
    "\n",
    "# ID3tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
