{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.20.2.\n",
      "The numpy version is 1.15.4.\n",
      "The scipy version is 1.2.1.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "import scipy\n",
    "\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "print('The numpy version is {}.'.format(np.__version__))\n",
    "print('The scipy version is {}.'.format(scipy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE --- check between predicted and target values for test and train data \n",
    "#before and after training\n",
    "import math as mh\n",
    "def MLP_Rmse(x,y):\n",
    "#Root Mean Square Error Function\n",
    "    RMSE = 0\n",
    "    for i in range(0,len(x)):\n",
    "        RMSE+= (x[i]-y[i])**2 #----Sum of Square Error\n",
    "    RMSE = RMSE/len(x)    \n",
    "    RMSE = mh.sqrt(RMSE)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the boston housing dataset\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(boston.data.shape)\n",
    "# type(boston)\n",
    "#print(boston)\n",
    "#506X13 bunch with data target feature_names and DESCR as keys (with values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(boston.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(boston.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the Input Matrix\n",
    "#Preprocessing\n",
    "from sklearn import preprocessing\n",
    "boston.data_standardized = preprocessing.scale(boston.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston.data_standardized, boston.target, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"x-train\") \n",
    "# print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"x-test\") \n",
    "# print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"y-train\") \n",
    "# print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"y-test\") \n",
    "# print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "\n",
    "# #RMSE 4.9\n",
    "# model = MLPRegressor(hidden_layer_sizes=(15), learning_rate = 'adaptive',\n",
    "#                      learning_rate_init = 0.10, max_iter = 4000,momentum = 0.9,random_state = 13)\n",
    "\n",
    "\n",
    "#RMSE 4.55\n",
    "model = MLPRegressor(max_iter = 2000,momentum = 0.9,random_state = 13)\n",
    "\n",
    "# model = MLPRegressor(random_state =13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=13, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get pre-training Weights and Output Values\n",
    "model.partial_fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 2000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 13, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#Get model parameters\n",
    "Params = model.get_params(deep = True)\n",
    "type(Params)\n",
    "print(Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 100)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "#Get Inital Parameters to compare pre-training and post-training\n",
    "\n",
    "InitialWeightsI_H = model.coefs_[0]\n",
    "# print(InitialWeightsI_H)\n",
    "print(np.shape(InitialWeightsI_H))\n",
    "\n",
    "InitialWeightsH_O = model.coefs_[1]\n",
    "# print(InitialWeightsH_O)\n",
    "print(np.shape(InitialWeightsH_O))\n",
    "\n",
    "\n",
    "#Find the bias weights\n",
    "Initial_BiasI_H = model.intercepts_[0]\n",
    "Initial_BiasH_O = model.intercepts_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on pre-trained network\n",
    "y_predict_train_pre_train = model.predict(x_train)\n",
    "y_predict_test_pre_train = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the RMSE for test and train data on pre-trained network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For train data, pretrain\n",
    "RMSE_Train_Pre_Train = MLP_Rmse(y_predict_train_pre_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Test Data, pretrain\n",
    "RMSE_Test_Pre_Train = MLP_Rmse(y_predict_test_pre_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=13, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the neural network\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict after training\n",
    "y_predict_train_post_train = model.predict(x_train)\n",
    "y_predict_test_post_train = model.predict(x_test)\n",
    "# print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 100)\n"
     ]
    }
   ],
   "source": [
    "#Get the weights matrix of the neural network \n",
    "\n",
    "FinalWeightsI_H = model.coefs_[0]\n",
    "# print(FinalWeightsI_H)\n",
    "print(np.shape(FinalWeightsI_H))\n",
    "\n",
    "FinalWeightsH_O = model.coefs_[1]\n",
    "# print(FinalWeightsH_O)\n",
    "# print(np.shape(FinalWeightsH_O))\n",
    "\n",
    "Final_BiasI_H = model.intercepts_[0]\n",
    "Final_BiasH_O = model.intercepts_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the RMSE for test and train data post-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for train data, post train\n",
    "RMSE_Train_Post_Train = MLP_Rmse(y_predict_train_post_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for test data, post train\n",
    "RMSE_Test_Post_Train = MLP_Rmse(y_predict_test_post_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('/Users/anumolubhargav/Documents/Machine Learning/Homework2/housesScaledResults.txt', 'w+')\n",
    "file.write(\"This is the best scaled run \\n\\n\\n\")\n",
    "file.write(\"PARAMETER DATA: \\n {} \\n \".format(Params)+ \"\\n\" + \"\\n\")\n",
    "file.write(\"Random Seed used: 13\\n\\n\")\n",
    "file.write(\"Number of Layers:  1\\n\\n\")\n",
    "file.write(\"Number of Hidden Nodes:  100\\n\\n\")\n",
    "file.write(\"Number of Epochs : 2000 (best run)\\n\\n\")\n",
    "\n",
    "#Weights and Biases before Training:\n",
    "file.write(\"Initial I-->H Weights:\\n {} \\n\".format(InitialWeightsI_H) + \"\\n\")\n",
    "file.write(\"Initial I-->H Bias:\\n {} \\n\".format(Initial_BiasI_H) + \"\\n\")\n",
    "\n",
    "file.write(\"Initial H-->O Weights:\\n {} \\n\".format(InitialWeightsH_O) + \"\\n\")\n",
    "file.write(\"Initial H-->O Bias:\\n {} \\n\".format(Initial_BiasH_O) + \"\\n\")\n",
    "\n",
    "#Target Values for Test Data and Actual Values for Test Data before training:\n",
    "\n",
    "file.write(\"Target Values for Test Data before Training: \\n {} \\n\".format(y_test) + \"\\n\")\n",
    "file.write(\"Output Values for Test Data before Training: \\n {} \\n\".format(y_predict_test_pre_train) + \"\\n\")\n",
    "\n",
    "\n",
    "#RMSE Values before training:\n",
    "file.write(\"RMSE Pre-Train Train Data:\\n {} \\n\".format(RMSE_Train_Pre_Train) + \"\\n\")\n",
    "file.write(\"RMSE Pre-Train Test Data:\\n {} \\n\".format(RMSE_Test_Pre_Train) + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#Weights and Biases after training:\n",
    "file.write(\"Final I-->H Weights:\\n {} \\n\".format(FinalWeightsI_H) + \"\\n\")\n",
    "file.write(\"Final I-->H Bias:\\n {} \\n\".format(Final_BiasI_H) + \"\\n\")\n",
    "\n",
    "file.write(\"Final H-->O Weights:\\n {} \\n\".format(FinalWeightsH_O) + \"\\n\")\n",
    "file.write(\"Final H-->O Bias:\\n {} \\n\".format(Final_BiasH_O) + \"\\n\")\n",
    "\n",
    "#Target Values for Test Data and Actual Values for Test Data before training:\n",
    "\n",
    "file.write(\"Target Values for Test Data post Training: \\n {} \\n\".format(y_test) + \"\\n\")\n",
    "file.write(\"Output Values for Test Data post Training: \\n {} \\n\".format(y_predict_test_post_train) + \"\\n\")\n",
    "\n",
    "#RMSE Values after training:\n",
    "file.write(\"RMSE Post-Train Train Data:\\n {} \\n\".format(RMSE_Train_Post_Train) + \"\\n\")\n",
    "file.write(\"RMSE Post-Train Test Data:\\n {} \\n\".format(RMSE_Test_Post_Train) + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
