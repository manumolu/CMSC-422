{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Code from Chapter 4 of Machine Learning: An Algorithmic Perspective (2nd Edition)\n",
    "# by Stephen Marsland (http://stephenmonika.net)\n",
    "\n",
    "# You are free to use, change, or redistribute the code in any way you wish for\n",
    "# non-commercial purposes, but please maintain the name of the original author.\n",
    "# This code comes with no warranty of any kind.\n",
    "\n",
    "# Stephen Marsland, 2008, 2014\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class mlp:\n",
    "    \"\"\" A Multi-Layer Perceptron\"\"\"\n",
    "    \n",
    "#     def __init__(self,inputs,targets,nhidden,beta=1,momentum=0.9,outtype='logistic'):\n",
    "    def __init__(self,inputs,targets,outfid,nhidden,beta=1,momentum=0.9,outtype='logistic'):\n",
    "        \n",
    "        self.fid = outfid ### edit made to write to new file \"MLP_Results.txt\"    <-------------#\n",
    "        \n",
    "        \"\"\" Constructor \"\"\"\n",
    "        # Set up network size\n",
    "        \n",
    "        self.nin = np.shape(inputs)[1]\n",
    "        self.nout = np.shape(targets)[1]\n",
    "        self.ndata = np.shape(inputs)[0]\n",
    "        self.nhidden = nhidden\n",
    "\n",
    "        self.beta = beta\n",
    "        self.momentum = momentum\n",
    "        self.outtype = outtype\n",
    "    \n",
    "        # Initialise network\n",
    "        self.weights1 = (np.random.rand(self.nin+1,self.nhidden)-0.5)*2/np.sqrt(self.nin)\n",
    "        self.weights2 = (np.random.rand(self.nhidden+1,self.nout)-0.5)*2/np.sqrt(self.nhidden)\n",
    "        \n",
    "        #######---------MANOHAR ANUMOLU UID 115733039-------#######\n",
    "        self.fid.write(\"Initial I-->H Weights:\\n {} \\n\".format(self.weights1) + \"\\n\")\n",
    "        self.fid.write(\"Initial H-->O Weights:\\n {} \\n\".format(self.weights2) + \"\\n\")\n",
    "        \n",
    "        #########-------------------------------------------########\n",
    "\n",
    "    def earlystopping(self,inputs,targets,valid,validtargets,eta,niterations=100):\n",
    "        \n",
    "        valid = np.concatenate((valid,-np.ones((np.shape(valid)[0],1))),axis=1)\n",
    "        \n",
    "        old_val_error1 = 100002\n",
    "        old_val_error2 = 100001\n",
    "        new_val_error = 100000\n",
    "        \n",
    "        count = 0\n",
    "        while (((old_val_error1 - new_val_error) > 0.001) or ((old_val_error2 - old_val_error1)>0.001)):\n",
    "            count+=1\n",
    "            print(count)\n",
    "            self.mlptrain(inputs,targets,eta,niterations)\n",
    "            old_val_error2 = old_val_error1\n",
    "            old_val_error1 = new_val_error\n",
    "            validout = self.mlpfwd(valid)\n",
    "            new_val_error = 0.5*np.sum((validtargets-validout)**2)\n",
    "            \n",
    "        print(\"Stopped\", new_val_error,old_val_error1, old_val_error2)\n",
    "        return new_val_error\n",
    "    \t\n",
    "    def mlptrain(self,inputs,targets,eta,niterations):\n",
    "        \"\"\" Train the thing \"\"\"    \n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = np.concatenate((inputs,-np.ones((self.ndata,1))),axis=1)\n",
    "        change = range(self.ndata)\n",
    "    \n",
    "        updatew1 = np.zeros((np.shape(self.weights1)))\n",
    "        updatew2 = np.zeros((np.shape(self.weights2)))\n",
    "            \n",
    "        for n in range(niterations):\n",
    "    \n",
    "            self.outputs = self.mlpfwd(inputs)\n",
    "\n",
    "            error = 0.5*np.sum((self.outputs-targets)**2)\n",
    "            if (np.mod(n,100)==0):\n",
    "                print(\"Iteration: \",n, \" Error: \",error)    \n",
    "\n",
    "            # Different types of output neurons\n",
    "            if self.outtype == 'linear':\n",
    "            \tdeltao = (self.outputs-targets)/self.ndata\n",
    "            elif self.outtype == 'logistic':\n",
    "            \tdeltao = self.beta*(self.outputs-targets)*self.outputs*(1.0-self.outputs)\n",
    "            elif self.outtype == 'softmax':\n",
    "                deltao = (self.outputs-targets)*(self.outputs*(-self.outputs)+self.outputs)/self.ndata \n",
    "            else:\n",
    "            \tprint(\"error\")\n",
    "            \n",
    "            deltah = self.hidden*self.beta*(1.0-self.hidden)*(np.dot(deltao,np.transpose(self.weights2)))\n",
    "                      \n",
    "            updatew1 = eta*(np.dot(np.transpose(inputs),deltah[:,:-1])) + self.momentum*updatew1\n",
    "            updatew2 = eta*(np.dot(np.transpose(self.hidden),deltao)) + self.momentum*updatew2\n",
    "            self.weights1 -= updatew1\n",
    "            self.weights2 -= updatew2\n",
    "         \n",
    "        ###########----Manohar Anumolu (UID 115733039)-----########\n",
    "\n",
    "        self.fid.write(\"Learning Rate:\\n {} \\n\".format(eta) + \"\\n\" + \"\\n\" )\n",
    "        self.fid.write(\"Number of Epochs:\\n {} \\n\".format(niterations) + \"\\n\" + \"\\n\" )\n",
    "        \n",
    "        self.fid.write(\"Final I---->H Weights:\\n {} \\n\".format(self.weights1) + \"\\n\" + \"\\n\")\n",
    "        self.fid.write(\"Final H---->O Weights:\\n {} \\n\".format(self.weights2) + \"\\n\" + \"\\n\")\n",
    "\n",
    "        ##########----------------------------------------######### \n",
    "        \n",
    "            # Randomise order of inputs (not necessary for matrix-based calculation)\n",
    "            #np.random.shuffle(change)\n",
    "            #inputs = inputs[change,:]\n",
    "            #targets = targets[change,:]\n",
    "            \n",
    "    def mlpfwd(self,inputs):\n",
    "        \"\"\" Run the network forward \"\"\"\n",
    "\n",
    "        self.hidden = np.dot(inputs,self.weights1);\n",
    "        self.hidden = 1.0/(1.0+np.exp(-self.beta*self.hidden))\n",
    "        self.hidden = np.concatenate((self.hidden,-np.ones((np.shape(inputs)[0],1))),axis=1)\n",
    "\n",
    "        outputs = np.dot(self.hidden,self.weights2);\n",
    "\n",
    "        # Different types of output neurons\n",
    "        if self.outtype == 'linear':\n",
    "        \treturn outputs\n",
    "        elif self.outtype == 'logistic':\n",
    "            return 1.0/(1.0+np.exp(-self.beta*outputs))\n",
    "        elif self.outtype == 'softmax':\n",
    "            normalisers = np.sum(np.exp(outputs),axis=1)*np.ones((1,np.shape(outputs)[0]))\n",
    "            return np.transpose(np.transpose(np.exp(outputs))/normalisers)\n",
    "        else:\n",
    "            print(\"error\")\n",
    "\n",
    "    def confmat(self,inputs,targets,msg):\n",
    "        \"\"\"Confusion matrix\"\"\"\n",
    "\n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = np.concatenate((inputs,-np.ones((np.shape(inputs)[0],1))),axis=1)\n",
    "        outputs = self.mlpfwd(inputs)\n",
    "        \n",
    "        nclasses = np.shape(targets)[1]\n",
    "\n",
    "        if nclasses==1:\n",
    "            nclasses = 2\n",
    "            outputs = np.where(outputs>0.5,1,0)\n",
    "        else:\n",
    "            # 1-of-N encoding\n",
    "            outputs = np.argmax(outputs,1)\n",
    "            targets = np.argmax(targets,1)\n",
    "\n",
    "        cm = np.zeros((nclasses,nclasses))\n",
    "        for i in range(nclasses):\n",
    "            for j in range(nclasses):\n",
    "                cm[i,j] = np.sum(np.where(outputs==i,1,0)*np.where(targets==j,1,0))\n",
    "         \n",
    "        \n",
    "        #####-------------------Manohar Anumolu UID 115733039----------#######\n",
    "        self.fid.write(msg + \"confusion matrix:\\n {} \\n\".format(cm))\n",
    "        self.fid.write(\"Fraction correct: {} \\n\".format(np.trace(cm)/np.sum(cm)) + \"\\n\")\n",
    "        ######----------------------------------------------------------#######\n",
    "        \n",
    "#         print (msg + \"Confusion matrix is:\")\n",
    "#         print (cm)\n",
    "#         print (\"Percentage Correct: \",np.trace(cm)/np.sum(cm)*100)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using same snippets as shown in previous homework  - Manohar Anumolu UID 115733039\n",
    "import numpy as np\n",
    "data = np.loadtxt(\"/Users/anumolubhargav/Documents/Machine Learning/Homework2/radarData.txt\",delimiter =\",\")\n",
    "# print(data)\n",
    "np.shape(data)\n",
    "#Observed 351 Rows and 35 Columns---last column is output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into test and train data--take every 5th sample for testing\n",
    "test = data[::5]\n",
    "\n",
    "train = np.delete(data, np.s_[::5], axis = 0)\n",
    "\n",
    "#Split into test and train inputs and outputs\n",
    "\n",
    "X_train = np.delete(train, -1, 1)\n",
    "# print(np.shape(X_train))\n",
    "# print(\" X Train : \" )\n",
    "# print(X_train)\n",
    "\n",
    "Y_train = np.delete(train, np.s_[:-1], 1)\n",
    "# print(np.shape(Y_train))\n",
    "# print(\" Y Train : \" )\n",
    "# print(Y_train)\n",
    "\n",
    "X_test = np.delete(test, -1, 1)\n",
    "# print(np.shape(X_test))\n",
    "# print(\" X Test : \" )\n",
    "# print(X_test)\n",
    "\n",
    "Y_test = np.delete(test, np.s_[:-1], 1)\n",
    "# print(np.shape(Y_test))\n",
    "# print(\" Y Test : \" )\n",
    "# print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Required in output file\n",
    "\n",
    "#1.Number of training examples\n",
    "#2.Number of testing examples\n",
    "#3.Learning Rate\n",
    "#4.Number of epochs\n",
    "#5.Number of Hidden Nodes\n",
    "\n",
    "#5. Initial Pre-Training Weights\n",
    "#6. Confusion Matrix - pre-training on training and testing data\n",
    "\n",
    "#7. Post training Weights\n",
    "#8. Confusion Matrix - post-training on training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0  Error:  131.03295164449702\n",
      "Iteration:  100  Error:  11.340965908792112\n",
      "Iteration:  200  Error:  8.613490982737408\n",
      "Iteration:  300  Error:  5.908369559788381\n",
      "Iteration:  400  Error:  4.604423695817452\n",
      "Iteration:  500  Error:  3.783265988503154\n",
      "Iteration:  600  Error:  3.2329903111634306\n",
      "Iteration:  700  Error:  2.8773490683915197\n",
      "Iteration:  800  Error:  2.630662638204424\n",
      "Iteration:  900  Error:  2.4434906007753305\n",
      "Iteration:  1000  Error:  2.2921679718191563\n",
      "Iteration:  1100  Error:  2.1645284048674878\n",
      "Iteration:  1200  Error:  2.054430295223952\n",
      "Iteration:  1300  Error:  1.9589967614570984\n",
      "Iteration:  1400  Error:  1.8763346718474967\n",
      "Iteration:  1500  Error:  1.8044917288452527\n",
      "Iteration:  1600  Error:  1.7414677727248478\n",
      "Iteration:  1700  Error:  1.6854940336864916\n",
      "Iteration:  1800  Error:  1.6351611256833674\n",
      "Iteration:  1900  Error:  1.589387595532143\n",
      "Iteration:  2000  Error:  1.5473445978385056\n",
      "Iteration:  2100  Error:  1.508398102058388\n",
      "Iteration:  2200  Error:  1.4720658565882843\n",
      "Iteration:  2300  Error:  1.4379763888147763\n",
      "Iteration:  2400  Error:  1.4058326212959504\n",
      "Iteration:  2500  Error:  1.3753878043572283\n",
      "Iteration:  2600  Error:  1.3464345582774566\n",
      "Iteration:  2700  Error:  1.3188014388856395\n",
      "Iteration:  2800  Error:  1.292351043324869\n",
      "Iteration:  2900  Error:  1.2669766474657616\n",
      "Iteration:  3000  Error:  1.2425970748649298\n",
      "Iteration:  3100  Error:  1.219150682873806\n",
      "Iteration:  3200  Error:  1.1965894481730248\n",
      "Iteration:  3300  Error:  1.1748738312496623\n",
      "Iteration:  3400  Error:  1.153968762466289\n",
      "Iteration:  3500  Error:  1.1338408238556534\n",
      "Iteration:  3600  Error:  1.1144565139201008\n"
     ]
    }
   ],
   "source": [
    "#Run the neural network\n",
    "file = open('/Users/anumolubhargav/Documents/Machine Learning/Homework2/MLP_Results.txt', 'w+')\n",
    "\n",
    "####-NETWORK INITIALIZATION \n",
    "#Initialize network to generate pre-trained weights\n",
    "model = mlp(X_train,Y_train,file,23,beta=1,momentum=0.9,outtype='linear')\n",
    "file.write(\"Number of Hidden Nodes: 23 \\n\\n\\n\")\n",
    "\n",
    "\n",
    "##CONFUSION MATRICES -- PRE-TRAINING\n",
    "#Find the confusion matrix for pre-trained training data\n",
    "model.confmat(X_train,Y_train,\"Pre-Trained Training Data -- \")\n",
    "#Find the confusion matrix for pre-trained testing data\n",
    "model.confmat(X_test,Y_test,\"Pre-Trained Testing Data -- \")\n",
    "\n",
    "#TRAINING THE NEURAL NETWORK\n",
    "file.write(\"\\n\\n\\n Training the neural network now....... \\n\\n\\n\")\n",
    "file.write(\"Number of Training Examples: \\n {} \\n \".format(np.shape(X_train)[0])+ \"\\n\" + \"\\n\")\n",
    "model.mlptrain(X_train, Y_train,0.25,3700) #--train the neural network\n",
    "\n",
    "####CONFUSION MATRICES -- POST-TRAINING\n",
    "#Find the confusion matrix for pre-trained training data\n",
    "model.confmat(X_train,Y_train,\"Post-Trained Training Data -- \")\n",
    "#Find the confusion matrix for pre-trained testing data\n",
    "model.confmat(X_test,Y_test,\"Post-Trained Testing Data -- \")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
